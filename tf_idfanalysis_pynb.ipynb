{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gywRBx5kzFUK",
        "outputId": "f5d63460-0cfe-437c-80f5-722de8c203e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "j4RAfaLYmXuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_excel('/content/drive/MyDrive/termfrequencyidfoutputmain.xlsx')\n",
        "\n",
        "# Now you can work with the DataFrame as needed\n",
        "print(df.head())  # Print the first few rows of the DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i69892_M39xB",
        "outputId": "56d19d03-5b77-4d6d-9894-252441035bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fitting      time     floor   setting    result   support     water  \\\n",
            "0  0.003381  0.005527  0.001845  0.003685  0.002859  0.001842  0.003116   \n",
            "1  0.000000  0.006298  0.004203  0.004198  0.003258  0.002099  0.003551   \n",
            "2  0.003806  0.006222  0.002077  0.004148  0.003219  0.002074  0.003508   \n",
            "3  0.003642  0.005955  0.001987  0.003970  0.003080  0.001985  0.000000   \n",
            "4  0.003426  0.005602  0.001869  0.003734  0.002898  0.001867  0.000000   \n",
            "\n",
            "     number      test    listed  ...   coating   shading  reflective  \\\n",
            "0  0.003689  0.002848  0.001845  ...  0.000000  0.000000    0.000000   \n",
            "1  0.002102  0.003245  0.002102  ...  0.003673  0.003673    0.003673   \n",
            "2  0.004153  0.003206  0.002077  ...  0.000000  0.000000    0.000000   \n",
            "3  0.003975  0.003068  0.001987  ...  0.000000  0.000000    0.000000   \n",
            "4  0.003739  0.002886  0.001869  ...  0.003267  0.003267    0.003267   \n",
            "\n",
            "    measure     local      loft    source   turbine  emission rate  \\\n",
            "0  0.000000  0.000000  0.000000  0.000000  0.000000         112.58   \n",
            "1  0.003627  0.000000  0.000000  0.000000  0.000000          41.31   \n",
            "2  0.000000  0.004635  0.000000  0.000000  0.003693          51.02   \n",
            "3  0.000000  0.000000  0.007370  0.000000  0.000000          73.17   \n",
            "4  0.003226  0.000000  0.006933  0.004649  0.000000         158.65   \n",
            "\n",
            "   consumption rate  \n",
            "0             659.0  \n",
            "1             291.6  \n",
            "2             302.0  \n",
            "3             433.0  \n",
            "4             938.0  \n",
            "\n",
            "[5 rows x 143 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_imputed = df.fillna(df.mean())\n",
        "\n",
        "# Check if missing values have been imputed\n",
        "print(\"Number of missing values in each column after imputation:\")\n",
        "print(df_imputed.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NttSJNc34htW",
        "outputId": "43753585-2a9f-43ff-b816-9c320062d9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing values in each column after imputation:\n",
            "fitting             0\n",
            "time                0\n",
            "floor               0\n",
            "setting             0\n",
            "result              0\n",
            "                   ..\n",
            "loft                0\n",
            "source              0\n",
            "turbine             0\n",
            "emission rate       0\n",
            "consumption rate    0\n",
            "Length: 143, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_imputed.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCi5y8925937",
        "outputId": "4585ef3b-96b8-4994-d28a-d8f9c61b4b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of        fitting      time     floor   setting    result   support     water  \\\n",
              "0     0.003381  0.005527  0.001845  0.003685  0.002859  0.001842  0.003116   \n",
              "1     0.000000  0.006298  0.004203  0.004198  0.003258  0.002099  0.003551   \n",
              "2     0.003806  0.006222  0.002077  0.004148  0.003219  0.002074  0.003508   \n",
              "3     0.003642  0.005955  0.001987  0.003970  0.003080  0.001985  0.000000   \n",
              "4     0.003426  0.005602  0.001869  0.003734  0.002898  0.001867  0.000000   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1180  0.000000  0.008280  0.002763  0.005520  0.000000  0.002760  0.000000   \n",
              "1181  0.000000  0.008280  0.002763  0.005520  0.000000  0.002760  0.000000   \n",
              "1182  0.000000  0.008280  0.002763  0.005520  0.000000  0.002760  0.000000   \n",
              "1183  0.000000  0.008280  0.002763  0.005520  0.000000  0.002760  0.000000   \n",
              "1184  0.000000  0.008280  0.002763  0.005520  0.000000  0.002760  0.000000   \n",
              "\n",
              "        number      test    listed  ...   coating   shading  reflective  \\\n",
              "0     0.003689  0.002848  0.001845  ...  0.000000  0.000000    0.000000   \n",
              "1     0.002102  0.003245  0.002102  ...  0.003673  0.003673    0.003673   \n",
              "2     0.004153  0.003206  0.002077  ...  0.000000  0.000000    0.000000   \n",
              "3     0.003975  0.003068  0.001987  ...  0.000000  0.000000    0.000000   \n",
              "4     0.003739  0.002886  0.001869  ...  0.003267  0.003267    0.003267   \n",
              "...        ...       ...       ...  ...       ...       ...         ...   \n",
              "1180  0.002763  0.000000  0.002763  ...  0.000000  0.000000    0.000000   \n",
              "1181  0.002763  0.000000  0.002763  ...  0.000000  0.000000    0.000000   \n",
              "1182  0.002763  0.000000  0.002763  ...  0.000000  0.000000    0.000000   \n",
              "1183  0.002763  0.000000  0.002763  ...  0.000000  0.000000    0.000000   \n",
              "1184  0.002763  0.000000  0.002763  ...  0.000000  0.000000    0.000000   \n",
              "\n",
              "       measure     local      loft    source   turbine  emission rate  \\\n",
              "0     0.000000  0.000000  0.000000  0.000000  0.000000         112.58   \n",
              "1     0.003627  0.000000  0.000000  0.000000  0.000000          41.31   \n",
              "2     0.000000  0.004635  0.000000  0.000000  0.003693          51.02   \n",
              "3     0.000000  0.000000  0.007370  0.000000  0.000000          73.17   \n",
              "4     0.003226  0.000000  0.006933  0.004649  0.000000         158.65   \n",
              "...        ...       ...       ...       ...       ...            ...   \n",
              "1180  0.000000  0.000000  0.000000  0.000000  0.000000          12.71   \n",
              "1181  0.000000  0.000000  0.000000  0.000000  0.000000         124.56   \n",
              "1182  0.000000  0.000000  0.000000  0.000000  0.000000          63.04   \n",
              "1183  0.000000  0.000000  0.000000  0.000000  0.000000         133.15   \n",
              "1184  0.000000  0.000000  0.000000  0.000000  0.000000          83.11   \n",
              "\n",
              "      consumption rate  \n",
              "0                659.0  \n",
              "1                291.6  \n",
              "2                302.0  \n",
              "3                433.0  \n",
              "4                938.0  \n",
              "...                ...  \n",
              "1180              98.0  \n",
              "1181             723.0  \n",
              "1182             363.0  \n",
              "1183             788.0  \n",
              "1184             291.6  \n",
              "\n",
              "[1185 rows x 143 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest**"
      ],
      "metadata": {
        "id": "v5BHodm8mllT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load your dataset into a Pandas DataFrame\n",
        "# Replace 'data.csv' with your actual data file\n",
        "df_imputed = pd.read_excel('/content/drive/MyDrive/termfrequencyidfoutputmain.xlsx')\n",
        "\n",
        "# Assuming 'target' is the column you want to predict\n",
        "X = df_imputed.drop('consumption rate', axis=1)  # Features\n",
        "y = df_imputed['consumption rate']  # Target variable\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest Regressor\n",
        "# You can customize the parameters based on your data and requirements\n",
        "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared:\", r2)\n",
        "print(\"Root Mean Squared Error:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8XfeXto61Yy",
        "outputId": "9b5f2e76-ae35-4921-82a2-221648e020b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 37194.652287086494\n",
            "R-squared: 0.5294557683739962\n",
            "Root Mean Squared Error: 192.85915142166962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest with Applied HyperParameter Optimisation**"
      ],
      "metadata": {
        "id": "j1mCtLOImx9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load your dataset\n",
        "df_imputed = pd.read_excel('/content/drive/MyDrive/termfrequencyidfoutputmain.xlsx')\n",
        "\n",
        "# Assuming 'consumption rate' is the column you want to predict\n",
        "target_column = 'consumption rate'\n",
        "\n",
        "# Prepare the data\n",
        "X = df_imputed.drop(target_column, axis=1)\n",
        "y = df_imputed[target_column]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a grid of hyperparameters to search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Initialize Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor()\n",
        "\n",
        "# Initialize Grid Search with Cross-Validation\n",
        "grid_search = GridSearchCV(rf_regressor, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Perform Grid Search on the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG6mph17ZYzd",
        "outputId": "9f750069-42b3-4153-a57d-cbc2b91424c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
            "Mean Squared Error: 40367.93181542719\n",
            "Root Mean Squared Error: 200.91772399523938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear Regression**"
      ],
      "metadata": {
        "id": "Gohb6ypNnFP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Assuming you have your dataset in a CSV file named 'your_dataset.csv'\n",
        "# Replace 'your_dataset.csv' with the actual file path\n",
        "\n",
        "# Load the dataset from CSV file\n",
        "df_imputed = pd.read_excel('/content/drive/MyDrive/termfrequencyidfoutputmain.xlsx')\n",
        "\n",
        "# Define the features (input variables) and target variable\n",
        "features = ['time', 'floor', 'analytics', 'high', 'change', 'consider', 'recommendation', 'low', 'medium', 'performance', 'year', 'heating', 'efficiency', 'emission rate', 'impact']\n",
        "target = 'consumption rate'\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = df_imputed[features]\n",
        "y = df_imputed[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "linear_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared:\", r2)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5uVTrAEW4ne",
        "outputId": "a8480087-8595-40a4-8165-8237fec0c0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 37321.90500762667\n",
            "R-squared: 0.5278459123886055\n",
            "Root Mean Squared Error: 193.1887807498838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multilayer Processing (MLP)**"
      ],
      "metadata": {
        "id": "9JfSEDqgnRoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset from Excel file\n",
        "df_imputed = pd.read_excel('/content/drive/MyDrive/termfrequencyidfoutputmain.xlsx')\n",
        "\n",
        "# Define the features (input variables) and target variable\n",
        "features = ['time', 'floor', 'analytics', 'high', 'change', 'consider', 'recommendation', 'low', 'medium', 'performance', 'year', 'heating', 'efficiency', 'emission rate', 'impact']\n",
        "target = 'consumption rate'\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = df_imputed[features]\n",
        "y = df_imputed[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Multi-Layer Perceptron (MLP) Regressor\n",
        "mlp_reg = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "mlp_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = mlp_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared:\", r2)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW1U3pHpwo_B",
        "outputId": "a2186d8b-6077-4c05-d6b5-66a7c92d25d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 39509.37581531185\n",
            "R-squared: 0.5001725317514676\n",
            "Root Mean Squared Error: 198.769655167261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}